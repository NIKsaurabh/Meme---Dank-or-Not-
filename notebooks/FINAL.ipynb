{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YgEJODEyj-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f9fec562-0574-4936-8dad-0204ce01c907"
      },
      "source": [
        "#installing pytesseract\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install tensorflow-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (3.12.4)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.34.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.8.0->tensorflow-text) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (2021.5.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iQk4OK4PZmSs",
        "outputId": "2f2eb37c-0a87-4deb-ad1c-31274eb50ac3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXrzEPa8mdi-"
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from drive.MyDrive.Applied_ai import sentiment    #importing python module\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_text as text\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.models import load_model\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "from PIL import Image\n",
        "import cv2 \n",
        "from skimage import io\n",
        "import pytesseract\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg_CSEmr66Lv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a101e93b-a06d-4617-eb15-69099cdf4f31"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkW9b7s8y4wX"
      },
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AkiFyiMvOpg"
      },
      "source": [
        "#reading the dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Applied_ai/test dataset/df_final_test.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IfqzRJSaYfX"
      },
      "source": [
        "#loading pre trained model and word index\n",
        "pred_model = keras.models.load_model('/content/drive/MyDrive/Applied_ai/best_model.hdf5')\n",
        "word_idx = json.load(open(\"/content/drive/MyDrive/Applied_ai/word_idx.txt\"))\n",
        "img_feature_model = VGG16()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8iKF99TeIAY"
      },
      "source": [
        "#range of HSV values to extract colors from the image\n",
        "boundries = [([0,0,200],[180,25,255]),      #white\n",
        "              ([0,0,0],[180,255,3]),        #black\n",
        "              ([0,0,100],[180,20,180]),        #gray\n",
        "              ([0,90,115],[17,255,190]),     #brown\n",
        "              ([20,50,240],[30,75,255]),     #off-white\n",
        "              ([0,140,155],[12,255,230]),      #dark red\n",
        "              ([0,140,230],[12,255,255]),     #light red\n",
        "              ([13,190,155],[17,255,230]),     #dark orange\n",
        "              ([13,140,230],[115,255,255]),    #light orange\n",
        "              ([18,140,155],[140,255,230]),     #goldish\n",
        "              ([23,140,230],[165,255,255]),    #yellow\n",
        "              ([28,90,155],[80,255,230]),    #dark green\n",
        "              ([85,77,153],[93,255,230]),   #dark cyan\n",
        "              ([85,77,230],[93,255,255]),  #cyan\n",
        "              ([100,128,90],[125,255,190]),   #dark blue\n",
        "              ([100,128,193],[125,255,255]),  #light blue\n",
        "              ([0,0,255],[180,25,255])      #faded colors\n",
        "]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GuY4kvnLL8D"
      },
      "source": [
        "<br>\n",
        "\n",
        "# **First Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrSt4C0So0hs"
      },
      "source": [
        "def function_1(data):\n",
        "  \n",
        "  df = data\n",
        "  \n",
        "  #lists to store extracted data from image\n",
        "  img_text = []\n",
        "  avg_h = []\n",
        "  avg_s = []\n",
        "  avg_v = []\n",
        "  all_colors = []\n",
        "  width = []\n",
        "  height = []\n",
        "  img_feature_pred_1 = []\n",
        "  img_feature_pred_2 = []\n",
        "  img_feature_pred_3 = []\n",
        "  website = []\n",
        "  book_jacket = []\n",
        "  packet = []\n",
        "  mud_turtle = []\n",
        "\n",
        "  print(\"\\n\\nPreparing data...\\n\")\n",
        "  #extracting data from images\n",
        "  for url in tqdm(data['url'], position=0):\n",
        "\n",
        "    path = '/content/drive/MyDrive/Applied_ai/meme_images/'+url\n",
        "    im = io.imread(path)\n",
        "\n",
        "    #extracting text\n",
        "    im_t = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    _, im_t = cv2.threshold(im_t, 127, 255, cv2.THRESH_BINARY) \n",
        "    custom_config = r\"--oem 3 --psm 11 -c tessedit_char_whitelist= 'ABCDEFGHIJKLMNOPQRSTUVWXYZ '\"\n",
        "    text = pytesseract.image_to_string(im_t, lang='eng', config=custom_config)\n",
        "    #print('text length',len(text.split(' ')))\n",
        "    text = text.replace('\\n', ' ')\n",
        "\n",
        "    #cleaning text\n",
        "    text = re.sub('[^A-Za-z]',' ',text).lower()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stopWords = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stopWords and len(w)>3]\n",
        "    img_text.append(' '.join(words))\n",
        "    \n",
        "    #extracting HSV\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    h,s,v = cv2.split(hsv)\n",
        "    avg_h.append(h.mean())\n",
        "    avg_s.append(s.mean())\n",
        "    avg_v.append(v.mean())\n",
        "    \n",
        "    #extracting colors from image\n",
        "    num_pixel = im.shape[0] * im.shape[1]\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    clr_pixel = []\n",
        "\n",
        "    for (lower, upper) in boundries:\n",
        "      lower = np.array(lower, dtype = \"uint8\")\n",
        "      upper = np.array(upper, dtype = \"uint8\")\n",
        "      mask = cv2.inRange(hsv, lower, upper)\n",
        "      clr_pixel.append(round(((mask==255).sum())/num_pixel,5)) #counting and normalizing number of pixels\n",
        "\n",
        "    all_colors.append(clr_pixel)\n",
        "    \n",
        "    #getting height and width of the image\n",
        "    hgt = im.shape[0]\n",
        "    wth = im.shape[1]\n",
        "    width.append(wth)\n",
        "    height.append(hgt)\n",
        "    \n",
        "    #extracting objects from image using VGG16\n",
        "    \n",
        "    pixels = np.asarray(im)\n",
        "    pixels = pixels.astype('float32')\n",
        "    pixels.resize(224,224,3)\n",
        "    pixels = np.expand_dims(pixels, axis=0)\n",
        "    pixels = preprocess_input(pixels)\n",
        "    im_prediction = img_feature_model.predict(pixels)\n",
        "    labels = decode_predictions(im_prediction, top=3)\n",
        "    \n",
        "    img_feature_pred_1.append(labels[0][0][2])\n",
        "    img_feature_pred_2.append(labels[0][1][2])\n",
        "    img_feature_pred_3.append(labels[0][2][2])\n",
        "\n",
        "    objects = [labels[0][0][1],labels[0][1][1],labels[0][2][1]]\n",
        "    for j in ['website','book_jacket','packet','mud_turtle']:\n",
        "        if j in objects:\n",
        "          exec(\"%s.append(%d)\" % (j,1))\n",
        "        else:\n",
        "          exec(\"%s.append(%d)\" % (j,0))\n",
        "\n",
        "    \n",
        "  \"\"\"combining extracted features from images to the dataset\"\"\"\n",
        "  \n",
        "  #text data\n",
        "  df['text'] = img_text\n",
        "  \n",
        "  #feature containing number of words in text\n",
        "  df['num_words'] = df['text'].str.split().apply(len)\n",
        "  \n",
        "  #getting sentiment score of the text data\n",
        "  df = sentiment.get_sentiment(pred_model, df, word_idx)\n",
        "  \n",
        "  #getting HSV value\n",
        "  df['avg_h'] = avg_h\n",
        "  df['avg_s'] = avg_s\n",
        "  df['avg_v'] = avg_v\n",
        "\n",
        "  #colors\n",
        "  colors = ['white','black','gray','brown','off-white','dark red','light red','dark orange','light orange',\n",
        "          'goldish','yellow','dark green','dark cyan','cyan','dark blue','light blue','faded colors']\n",
        "  #adding new color features to the dataset\n",
        "  for i, color in enumerate(colors):\n",
        "    df[color] = np.matrix(all_colors)[:,i]\n",
        "\n",
        "  #thumbnail height and width\n",
        "  df['thumbnail_height'] = height\n",
        "  df['thumbnail_width']  = width\n",
        "\n",
        "  #probability of occurance of objects in the image\n",
        "  df['img_feature_pred_1'] = img_feature_pred_1\n",
        "  df['img_feature_pred_2'] = img_feature_pred_2\n",
        "  df['img_feature_pred_3'] = img_feature_pred_3\n",
        "\n",
        "  #objects in the image\n",
        "  df['web_site'] = website\n",
        "  df['book_jacket'] = book_jacket\n",
        "  df['packet'] = packet\n",
        "  df['mud_turtle'] = mud_turtle\n",
        "\n",
        "  \"\"\"Defining different features for our different models\"\"\"\n",
        "\n",
        "  #dataset for ML model\n",
        "  X_ml = df[['img_feature_pred_1','img_feature_pred_2','img_feature_pred_3','avg_h','avg_s','avg_v','Sentiment_Score','hour',\n",
        "    'num_words','thumbnail_height','thumbnail_width','gray', 'white', 'faded colors', 'black', 'dark blue', 'goldish',\n",
        "    'light blue', 'brown', 'yellow', 'dark cyan', 'light orange', 'dark green', 'cyan', 'off-white', 'dark red', \n",
        "    'dark orange', 'light red','web_site','book_jacket','packet','mud_turtle']]\n",
        "\n",
        "  #dataset for CNN model\n",
        "  X_cnn = df[['url']]\n",
        "  \n",
        "  #dataset for NLP model\n",
        "  X_bert = df['text']\n",
        "\n",
        "  print(\"Data preparation done.\\n\")\n",
        "\n",
        "  \"\"\"loading models\"\"\"\n",
        "  print(\"Loading models...\\n\")\n",
        "  #ML model\n",
        "  ml_model = pickle.load(open('/content/drive/MyDrive/Applied_ai/models/dankornot_ml/dankornot_ml.pkl', 'rb'))\n",
        "\n",
        "  #CNN model\n",
        "  cnn_model = load_model('/content/drive/MyDrive/Applied_ai/models/resnet_model/resnet_model.h5')\n",
        "\n",
        "  #bert model\n",
        "  bert_model = tf.saved_model.load('/content/drive/MyDrive/Applied_ai/models/bert_model/content/bert_model')\n",
        "  \n",
        "  \"\"\"Predictions\"\"\"\n",
        "  print(\"Predicting...\\n\")\n",
        "  \n",
        "  #predicting using ML model\n",
        "  ml_pred_prob = ml_model.predict_proba(X_ml)[:,-1]\n",
        "  \n",
        "  #predicting using CNN model\n",
        "  cnn_pred_prob = []\n",
        "  for image in X_cnn.url:\n",
        "    path = '/content/drive/MyDrive/Applied_ai/meme_images/'+image\n",
        "    img = Image.open(path)\n",
        "    pixels = np.asarray(img)\n",
        "    pixels = pixels.astype('float32')\n",
        "    pixels /= 255.0\n",
        "    pixels.resize(224,224,3)\n",
        "    pixels = np.expand_dims(pixels, axis=0)\n",
        "    cnn_prediction = cnn_model.predict(pixels)\n",
        "    cnn_pred_prob.append(cnn_prediction[0][0])\n",
        "  \n",
        "  #predicting using NLP model\n",
        "  nlp_pred_prob = []\n",
        "  for text in X_bert:\n",
        "    try:\n",
        "      bert_predict = tf.sigmoid(bert_model(tf.constant([text])))\n",
        "      nlp_pred_prob.append(np.array(bert_predict)[0][0])\n",
        "    except:\n",
        "      nlp_pred_prob.append(0)\n",
        "\n",
        "  #creating a dataset of all predicted probabilities\n",
        "  prob_pred_df = pd.DataFrame(columns = ['ml_pred','cnn_pred','nlp_pred'])\n",
        "  prob_pred_df['ml_pred'] = ml_pred_prob\n",
        "  prob_pred_df['cnn_pred'] = cnn_pred_prob\n",
        "  prob_pred_df['nlp_pred'] = nlp_pred_prob\n",
        "\n",
        "  #taking mean of predicted probabilities of each data and getting label according to that\n",
        "  mean_all = prob_pred_df.mean(axis=1)\n",
        "  label_all = mean_all.round().astype('int')\n",
        "\n",
        "  print(\"Done:)\")\n",
        "  #returning predicted labels\n",
        "  #return (np.array(label_all))\n",
        "  return np.array(label_all)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aWTZprEslVU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d8918ae9-ba4d-4154-9fe6-ea3eca3d9311"
      },
      "source": [
        "#calling function_1\n",
        "predicted_labels = function_1(dataset.sample(25))\n",
        "print('\\nPredictiction : ', predicted_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Preparing data...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data preparation done.\n",
            "\n",
            "Loading models...\n",
            "\n",
            "Predicting...\n",
            "\n",
            "Done:)\n",
            "\n",
            "Predictiction :  [0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xd_Y9aOLXrZ"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "# **Second Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbknPsqJSye6"
      },
      "source": [
        "def function_2(data):\n",
        "  \n",
        "  df = data\n",
        "  \n",
        "  #lists to store extracted data from image\n",
        "  img_text = []\n",
        "  avg_h = []\n",
        "  avg_s = []\n",
        "  avg_v = []\n",
        "  all_colors = []\n",
        "  width = []\n",
        "  height = []\n",
        "  img_feature_pred_1 = []\n",
        "  img_feature_pred_2 = []\n",
        "  img_feature_pred_3 = []\n",
        "  website = []\n",
        "  book_jacket = []\n",
        "  packet = []\n",
        "  mud_turtle = []\n",
        "\n",
        "  print(\"\\n\\nPreparing data...\\n\")\n",
        "  #extracting data from images\n",
        "  for url in tqdm(data['url'], position=0):\n",
        "\n",
        "    #extracting text\n",
        "    path = '/content/drive/MyDrive/Applied_ai/meme_images/'+url\n",
        "    im = io.imread(path)\n",
        "    im_t = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    _, im_t = cv2.threshold(im_t, 127, 255, cv2.THRESH_BINARY) \n",
        "    custom_config = r\"--oem 3 --psm 11 -c tessedit_char_whitelist= 'ABCDEFGHIJKLMNOPQRSTUVWXYZ '\"\n",
        "    text = pytesseract.image_to_string(im_t, lang='eng', config=custom_config)\n",
        "    text = text.replace('\\n', ' ')\n",
        "\n",
        "    #cleaning text\n",
        "    text = re.sub('[^A-Za-z]',' ',text).lower()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stopWords = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stopWords and len(w)>3]\n",
        "    img_text.append(' '.join(words))\n",
        "\n",
        "    #extracting HSV\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    h,s,v = cv2.split(hsv)\n",
        "    avg_h.append(h.mean())\n",
        "    avg_s.append(s.mean())\n",
        "    avg_v.append(v.mean())\n",
        "\n",
        "    #extracting colors from image\n",
        "    num_pixel = im.shape[0] * im.shape[1]\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    clr_pixel = []\n",
        "\n",
        "    for (lower, upper) in boundries:\n",
        "      lower = np.array(lower, dtype = \"uint8\")\n",
        "      upper = np.array(upper, dtype = \"uint8\")\n",
        "      mask = cv2.inRange(hsv, lower, upper)\n",
        "      clr_pixel.append(round(((mask==255).sum())/num_pixel,5)) #counting and normalizing number of pixels\n",
        "\n",
        "    all_colors.append(clr_pixel)\n",
        "\n",
        "    #getting height and width of the image\n",
        "    hgt = im.shape[0]\n",
        "    wth = im.shape[1]\n",
        "    width.append(wth)\n",
        "    height.append(hgt)\n",
        "\n",
        "    #extracting objects from image using VGG16\n",
        "    pixels = np.asarray(im)\n",
        "    pixels = pixels.astype('float32')\n",
        "    pixels.resize(224,224,3)\n",
        "    pixels = np.expand_dims(pixels, axis=0)\n",
        "    pixels = preprocess_input(pixels)\n",
        "    im_prediction = img_feature_model.predict(pixels)\n",
        "    labels = decode_predictions(im_prediction, top=3)\n",
        "    \n",
        "    img_feature_pred_1.append(labels[0][0][2])\n",
        "    img_feature_pred_2.append(labels[0][1][2])\n",
        "    img_feature_pred_3.append(labels[0][2][2])\n",
        "\n",
        "    objects = [labels[0][0][1],labels[0][1][1],labels[0][2][1]]\n",
        "    for j in ['website','book_jacket','packet','mud_turtle']:\n",
        "        if j in objects:\n",
        "          exec(\"%s.append(%d)\" % (j,1))\n",
        "        else:\n",
        "          exec(\"%s.append(%d)\" % (j,0))\n",
        "\n",
        "\n",
        "  \"\"\"combining extracted features from images to the dataset\"\"\"\n",
        "  \n",
        "  #text data\n",
        "  df['text'] = img_text\n",
        "  \n",
        "  #feature containing number of words in text\n",
        "  df['num_words'] = df['text'].str.split().apply(len)\n",
        "\n",
        "  #getting sentiment score of the text data\n",
        "  df = sentiment.get_sentiment(pred_model, df, word_idx)\n",
        "\n",
        "  #getting HSV value\n",
        "  df['avg_h'] = avg_h\n",
        "  df['avg_s'] = avg_s\n",
        "  df['avg_v'] = avg_v\n",
        "\n",
        "  #colors\n",
        "  colors = ['white','black','gray','brown','off-white','dark red','light red','dark orange','light orange',\n",
        "          'goldish','yellow','dark green','dark cyan','cyan','dark blue','light blue','faded colors']\n",
        "  #adding new color features to the dataset\n",
        "  for i, color in enumerate(colors):\n",
        "    df[color] = np.matrix(all_colors)[:,i]\n",
        "\n",
        "  #thumbnail height and width\n",
        "  df['thumbnail_height'] = height\n",
        "  df['thumbnail_width']  = width\n",
        "\n",
        "  #probability of occurance of objects in the image\n",
        "  df['img_feature_pred_1'] = img_feature_pred_1\n",
        "  df['img_feature_pred_2'] = img_feature_pred_2\n",
        "  df['img_feature_pred_3'] = img_feature_pred_3\n",
        "\n",
        "  #objects in the image\n",
        "  df['web_site'] = website\n",
        "  df['book_jacket'] = book_jacket\n",
        "  df['packet'] = packet\n",
        "  df['mud_turtle'] = mud_turtle\n",
        "\n",
        "  \"\"\"Defining different features for our different models\"\"\"\n",
        "\n",
        "  #dataset for ML model\n",
        "  X_ml = df[['img_feature_pred_1','img_feature_pred_2','img_feature_pred_3','avg_h','avg_s','avg_v','Sentiment_Score','hour',\n",
        "    'num_words','thumbnail_height','thumbnail_width','gray', 'white', 'faded colors', 'black', 'dark blue', 'goldish',\n",
        "    'light blue', 'brown', 'yellow', 'dark cyan', 'light orange', 'dark green', 'cyan', 'off-white', 'dark red', \n",
        "    'dark orange', 'light red','web_site','book_jacket','packet','mud_turtle']]\n",
        "\n",
        "  #dataset for CNN model\n",
        "  X_cnn = df[['url']]\n",
        "  \n",
        "  #dataset for NLP model\n",
        "  X_bert = df['text']\n",
        "\n",
        "  print(\"\\nData preparation done.\\n\")\n",
        "\n",
        "  \"\"\"loading models\"\"\"\n",
        "  print(\"Loading models...\\n\")\n",
        "  #ML model\n",
        "  ml_model = pickle.load(open('/content/drive/MyDrive/Applied_ai/models/dankornot_ml/dankornot_ml.pkl', 'rb'))\n",
        "\n",
        "  #CNN model\n",
        "  cnn_model = load_model('/content/drive/MyDrive/Applied_ai/models/resnet_model/resnet_model.h5')\n",
        "\n",
        "  #bert model\n",
        "  bert_model = tf.saved_model.load('/content/drive/MyDrive/Applied_ai/models/bert_model/content/bert_model')\n",
        "\n",
        "  \"\"\"Predictions\"\"\"\n",
        "  print(\"Predicting labels...\\n\")\n",
        "  #predicting using ML model\n",
        "  ml_pred_prob = ml_model.predict_proba(X_ml)[:,-1]\n",
        "\n",
        "  #predicting using CNN model\n",
        "  cnn_pred_prob = []\n",
        "  for image in X_cnn.url:\n",
        "    path = '/content/drive/MyDrive/Applied_ai/meme_images/'+image\n",
        "    img = Image.open(path)\n",
        "    pixels = np.asarray(img)\n",
        "    pixels = pixels.astype('float32')\n",
        "    pixels /= 255.0\n",
        "    pixels.resize(224,224,3)\n",
        "    pixels = np.expand_dims(pixels, axis=0)\n",
        "    cnn_prediction = cnn_model.predict(pixels)\n",
        "    cnn_pred_prob.append(cnn_prediction[0][0])\n",
        "\n",
        "  #predicting using NLP model\n",
        "  nlp_pred_prob = []\n",
        "  for text in X_bert:\n",
        "    try:\n",
        "      bert_predict = tf.sigmoid(bert_model(tf.constant([text])))\n",
        "      nlp_pred_prob.append(np.array(bert_predict)[0][0])\n",
        "    except:\n",
        "      nlp_pred_prob.append(0)\n",
        "\n",
        "  #creating a dataset of all predicted probabilities\n",
        "  prob_pred_df = pd.DataFrame(columns = ['ml_pred','cnn_pred','nlp_pred'])\n",
        "  prob_pred_df['ml_pred'] = ml_pred_prob\n",
        "  prob_pred_df['cnn_pred'] = cnn_pred_prob\n",
        "  prob_pred_df['nlp_pred'] = nlp_pred_prob\n",
        "\n",
        "  #taking mean of predicted probabilities of each data and getting label according to that\n",
        "  mean_all = prob_pred_df.mean(axis=1)\n",
        "  label_all = mean_all.round().astype('int')\n",
        "\n",
        "  print(\"Prediction done\\n\")\n",
        "  print(\"Computing accuracy...\\n\")\n",
        "  accuracy = accuracy_score(df['dank_or_not'], label_all)\n",
        "  print(\"Done:)\")\n",
        "\n",
        "  #returning predicted labels\n",
        "  return(accuracy, label_all)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVCg55P8HesA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e6a140-9139-42b9-afb0-59e673237349"
      },
      "source": [
        "#calling function_2\n",
        "df_2 = dataset.sample(500)\n",
        "accuracy, labels = function_2(df_2)\n",
        "print('\\nAccuracy : ', accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Preparing data...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [17:18<00:00,  2.08s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Data preparation done.\n",
            "\n",
            "Loading models...\n",
            "\n",
            "Predicting labels...\n",
            "\n",
            "Prediction done\n",
            "\n",
            "Computing accuracy...\n",
            "\n",
            "Done:)\n",
            "\n",
            "Accuracy :  0.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM2VVQ28Hlm5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7c088600-400b-4a57-a8de-66b141ff7493"
      },
      "source": [
        "#plotting confusion matrix\n",
        "cm = confusion_matrix(df_2['dank_or_not'], labels)\n",
        "sns.heatmap(cm, annot=True, fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEGCAYAAABFBX+4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW0ElEQVR4nO3de7xnc7nA8c8zZjAuk3E9zKhGjEPqdBnyqjgYCcnQhaFOiDMy6CSVdEPqHKVTRHIm9yMzlEjlFslwMplBLuPWxGAGScglxuy9n/PHb820jT17fnvP/u21v9vn7bVefr/vWvu7nvGanv30rO9aKzITSVI5htQdgCSpZ0zcklQYE7ckFcbELUmFMXFLUmGG1h3A0ix88gGXu+hVRmy4fd0haAB68cWHYnnn6EnOGbb2Rst9vuVhxS1JhRmwFbck9auO9rojaJqJW5IA2tvqjqBpJm5JAjI76g6haSZuSQLoMHFLUlmsuCWpMF6clKTCWHFLUlnSVSWSVBgvTkpSYWyVSFJhvDgpSYWx4pakwnhxUpIK48VJSSpLpj1uSSqLPW5JKoytEkkqjBW3JBWmfWHdETTNxC1JYKtEkopjq0SSCmPFLUmFKShxD6k7AEkaCLJ9YdPbskTEWRHxRETctcT44RFxb0TMjohvdxo/OiLmRMR9EfH+Zc1vxS1J0Nc97nOAU4HzFg1ExPbABOBfMnNBRKxbjW8OTATeDGwAXBMRY7ObWzmtuCUJGq2SZrdlyMzpwFNLDB8CnJCZC6pjnqjGJwDTMnNBZj4IzAG26m5+E7ckQaPibnKLiEkRMavTNqmJM4wFtomI30fE9RGxZTU+Cnik03HzqrGlslUiSdCji5OZOQWY0sMzDAXWBLYGtgQuioiNejjH4okkSa1fxz0P+FlmJnBzRHQAawPzgQ07HTe6GlsqWyWSBNDW1vzWO5cC2wNExFhgReBJ4DJgYkSsFBFjgE2Am7ubyIpbkqBPK+6ImApsB6wdEfOAY4CzgLOqJYIvA/tV1ffsiLgIuBtoAw7tbkUJmLglqaEPb8DJzH2WsuvjSzn+m8A3m53fxC1J4LNKJKk4Bd3ybuKWJLDilqTi9H61SL8zcUsSQGbdETTNxC1JYI9bkopj4pakwnhxUpIK097tzYoDiolbksBWiSQVx8QtSYWxxy1JZckO13FLUllslUhSYVxVIkmFseKWpMKYuNUTX/nP7zL9/25mzZFrcOn5pwNw5Ff/i7kPzwPgueefZ/XVVuPic3/A726+lZNOP5uFC9sYNmwoRx56IO9659vqDF/94PDDD2T//SeSmcyefS+TJn2eAw6YyGGHfZI3vemNjB79Nv7616frDrNsPmRKPbHHru9j3w/vzpeO/87isf8+/ujFn0885UestuoqAIxcYwSnfutY1l1nLf74wFwOPuIr/Obn5/d7zOo/G2ywHpMnH8Db3z6el15awPnn/4CPfvSD3HTTLC6//Fquvnpa3SEODlbcEBH/DEwARlVD84HLMvOeVp2zVOPe9hbmP/bnLvdlJlf+Zjpnff8EADYbu/HifRuPeQMvLVjAyy+/zIorrtgvsaoeQ4euwPDhK7NwYRvDhw/nscf+zO23z647rMGloOWAQ1oxaUQcBUwDgsZr5m+uPk+NiC+24pyD1S2338VaI0fyhg1HvWrfr397I5tvurFJe5B79NE/c9JJU7j//pt48MGZPPvsc1x77Q11hzX4tLc3v9WsJYkbOBDYMjNPyMzzq+0EYKtqX5ciYlJEzIqIWWecN7VFoZXl8l//ll3f96+vGp/zwEN897Sz+NrnD68hKvWnNdYYwW677cRmm72XjTbailVXHc7EiXvWHdagkx0dTW91a1Xi7gA26GJ8/WpflzJzSmaOy8xxB31iaW+3f+1oa2vnmut/x87jt33F+ONP/IX/+NLx/OdXP8frR3f1n1mDyQ47vJe5cx/hySefoq2tjUsvvZKtt35n3WENPh3Z/FazVvW4PwNcGxF/BB6pxl4PbAwc1qJzDjozZt3GRm8YzT+tu87isWefe57Jnz+Gz3zqAN7x1jfXGJ36yyOPPMpWW72d4cNX5sUXX2L77d/DrbfeWXdYg09BzyppScWdmVcCY4HjgKuq7Vhg02qfOvn8MSfwsYOPYO7D8xi/x8e5+BdXAXDFNdezy47bveLYqRf/gkfmPcrpZ1/Ah/c7lA/vdyh/ffqZGqJWf5k58w9ccsnl3HTTr5g162qGDBnCmWdewOTJ+zNnzgxGjVqfmTOv4rTTvlV3qGUrqOKOHKBrFxc++cDADEy1GrHh9nWHoAHoxRcfiuWd44WvTWw656z69WnLfb7l4TpuSYKiWiUmbkmCAdECaZaJW5JgQCzza5aJW5LAiluSimPilqTCDIBb2Ztl4pYkfOekJJXHxC1JhXFViSQVxopbkgpj4paksmR7Oa2SVj2PW5LK0odPB4yIsyLiiYi4q4t9R0ZERsTa1feIiO9HxJyIuCMi3rGs+U3ckkRjOWCzWxPOAXZecjAiNgR2Ah7uNLwLsEm1TQJ+uKzJTdySBH1acWfmdOCpLnZ9D/gC0HmSCcB52TADWCMi1u9ufhO3JEHjpYpNbp3fj1ttk5Y1fURMAOZn5u1L7BrFP94UBjCvGlsqL05KEpBtzV+czMwpwJRmj4+IVYAv0WiTLDcTtyRBN68x7xNvAsYAt0cEwGjg1ojYCpgPbNjp2NHV2FKZuCWJ1j6rJDPvBNZd9D0i5gLjMvPJiLgMOCwipgHvAv6WmY91N589bkmCHvW4lyUipgI3AZtGxLyIOLCbwy8HHgDmAD8CJi9rfituSaJvK+7M3GcZ+9/Y6XMCh/ZkfhO3JEGre9x9ysQtSUC21R1B80zckgSkFbckFcbELUllseKWpMKYuCWpMNkedYfQNBO3JGHFLUnFyQ4rbkkqihW3JBUm04pbkopixS1JhelwVYkklcWLk5JUGBO3JBUmW/cCnD631MQdEafwylfIv0JmfrolEUlSDQZLxT2r36KQpJoNiuWAmXlufwYiSXVqH0yrSiJiHeAoYHNg5UXjmblDC+OSpH5VUsXdzFvefwzcA4wBjgPmAjNbGJMk9bvsiKa3ujWTuNfKzDOBhZl5fWZ+ErDaljSoZDa/1a2Z5YALq38/FhEfAB4F1mxdSJLU/wZCJd2sZhL3NyLidcCRwCnACOCIlkYlSf2svaOZBsTAsMzEnZm/rD7+Ddi+teFIUj0GQgukWc2sKjmbLm7EqXrdkjQodBS0qqSZVskvO31eGdiTRp9bkgaNkpYDNtMqubjz94iYCtzYsogkqQaDqlXShU2Adfs6kCUN32CbVp9CBXph9k/qDkGD1KBqlUTEc7yyx/04jTspJWnQGGyrSlbvj0AkqU4FdUqWfedkRFzbzJgklawjo+mtbt09j3tlYBVg7YgYCSyKdgQwqh9ik6R+M1hWlRwMfAbYALiFfyTuZ4FTWxyXJPWrgl7y3u3zuE8GTo6IwzPzlH6MSZL6XVJOxd3MZdSOiFhj0ZeIGBkRk1sYkyT1u7aMpre6NZO4/z0zn1n0JTOfBv69dSFJUv9Loumtbs3cgLNCRERm476iiFgBWLG1YUlS/yqpx91MxX0lcGFEjI+I8cBU4IrWhiVJ/asvK+6IOCsinoiIuzqNnRgR90bEHRFxyRIt6KMjYk5E3BcR71/W/M0k7qOA3wCfqrY7geFN/JwkFaOjB1sTzgF2XmLs18AWmflW4H7gaICI2ByYCLy5+pnTqs7GUi0zcWdmB/B7Gu+a3IrGa8vuaS52SSpDO9H0tiyZOR14aomxqzOzrfo6AxhdfZ4ATMvMBZn5IDCHRq5dqu5uwBkL7FNtTwIXVif3ZQqSBp2evLksIiYBkzoNTcnMKT043SepciqNGxpndNo3j2Xc5Njdxcl7gRuA3TJzThWsryyTNCh19GC1SJWke5KoF4uILwNtwI978/PQfavkQ8BjwHUR8aPqwmT962AkqQWyB1tvRcT+wG7Axxat1APmAxt2Omx0NbZUS03cmXlpZk4E/hm4jsbt7+tGxA8jYqfliF2SBpw+vjj5KhGxM/AFYPfM/HunXZcBEyNipYgYQ+OdBzd3N1czFydfyMwLMvODNH4T3IbP45Y0yHRENL0tS/WmsJuATSNiXkQcSOMZT6sDv46IP0TE6QCZORu4CLibxvLrQzOzvbv5e/QGnOquyV73diRpoOo2U/ZQZu7TxfCZ3Rz/TeCbzc7fm1eXSdKg05NVJXUzcUsSPVtVUjcTtyRR1qvLTNyShK0SSSpOSU8HNHFLEtBuxS1JZbHilqTCmLglqTAD4FWSTTNxSxJW3JJUnL685b3VTNyShOu4Jak4tkokqTAmbkkqjM8qkaTC2OOWpMK4qkSSCtNRULPExC1JeHFSkopTTr1t4pYkwIpbkorTFuXU3CZuScJWiSQVx1aJJBXG5YCSVJhy0raJW5IAWyWSVJz2gmpuE7ckYcUtScVJK25JKosVt3pt7Ng3ccGPf7j4+0ZjXs+xx32H317/O0479QRWXW0VHnpoHv/2icN47rnna4xUrfa1k87k+pm3s+brRnDJad9YPH7BL65h2q+uZYUhQ9hm3L/w2U/uxcK2No79/tnc86eHaG/v4IM7vJuD9tqtxujL43JA9dr99/+JcVvuBMCQIUN4eO4tXPrzK7hw2hSOOup4pt8wg/3325vPHXkIxxx7Ys3RqpV23/G9TNxtPF/+7hmLx26+4x6um3EbPz3l66w4bBh/feZZAK6+cSYLF7bxsx98gxdfWsCek7/MLv+6NaPWW7uu8ItTTtqGIXUHoKUbv8N7eeCBh3j44fmM3WQjpt8wA4Brrr2BPffctebo1GrjttiU162+2ivGLrr8Og786K6sOGwYAGutMQKAiODvLy2grb2dBS8vZNjQoay2ysr9HnPJ2simt7qZuAewvfaawLQLLwXg7rvvZ/fd3w/ARz68GxuO3qDO0FSTh+Y/zi2z72ffzx7PAV88gbvufwCA971nHKusvBLj/+0z7HTAkez3oZ1flfTVvezBP3Xr98QdEQd0s29SRMyKiFkdHS/0Z1gDzrBhw/jgbjvx04t/CcBBkz7LIQfvx+9nXMHqq6/Kyy8vrDlC1aGtvYNnn3uBH//3V/jsAXvxuW/9kMzkrvsfZMiQIVxz3ve44swTOfeSq5j3+BN1h1uUjh5sdaujx30ccHZXOzJzCjAFYOiKo+r/tVajnXfenttuu5MnnngSgPvu+xO7fGBfADbZZCN23WV8neGpJuutPZLx734nEcFbNt2IIRE8/exzXH79DN7zzrcwbOhQ1lpjBG/fbGNm/3Euo/9p3bpDLsZAqKSb1ZKKOyLuWMp2J7BeK8452Ezce4/FbRKAddZZC2j0Mr909H/wP1P+t67QVKMdtn4HM++4F4C58x9nYVsbI0eszvrrrMnNd9wDwN9fWsAd9z3AmNHr1xlqcay4G8n5/cDTS4wH8LsWnXPQWGWV4ew4flsOmXzU4rGJe+/BIYfsD8Cll17OOedeWFN06i9f+PbpzLrzXp559nl23O+zTP7YHuz5vm342slnsufkrzBs2Ap844iDiAgmfmA8Xz3pTPac/GUyYcKO72XsmA3r/iMUpT37ruKOiLOA3YAnMnOLamxN4ELgjcBcYK/MfDoiAjgZ2BX4O7B/Zt7a7fzZh8F2CvpM4OzMvLGLfRdk5r7LmuO13ipR116Y/ZO6Q9AAtNIm747lnWPfN+zZdM654KFLuj1fRGwLPA+c1ylxfxt4KjNPiIgvAiMz86iI2BU4nEbifhdwcma+q7v5W9IqycwDu0ra1b5lJm1J6m99uaokM6cDTy0xPAE4t/p8LrBHp/HzsmEGsEZEdNvncjmgJNGzHnfnFXDVNqmJU6yXmY9Vnx/nH9f7RgGPdDpuXjW2VN45KUn07Jb3zivgeiMzM6L3bye24pYk+uUGnD8vaoFU/1600H4+0PlK8uhqbKlM3JJEY1VJs1svXQbsV33eD/h5p/FPRMPWwN86tVS6ZKtEkujbpwNGxFRgO2DtiJgHHAOcAFwUEQcCDwF7VYdfTmNFyRwaywGXenf5IiZuSaJvb6zJzH2WsutVtzxnY032oT2Z38QtSZR1y7uJW5LwRQqSVJxW3EXeKiZuSQLarbglqSy2SiSpMLZKJKkwVtySVBiXA0pSYfryRQqtZuKWJGyVSFJxTNySVBhXlUhSYay4JakwriqRpMK0Z18+2LW1TNyShD1uSSqOPW5JKow9bkkqTIetEkkqixW3JBXGVSWSVBhbJZJUGFslklQYK25JKowVtyQVpj3b6w6haSZuScJb3iWpON7yLkmFseKWpMK4qkSSCuOqEkkqjLe8S1Jh7HFLUmHscUtSYay4JakwruOWpMKUVHEPqTsASRoI2rOj6W1ZIuKIiJgdEXdFxNSIWDkixkTE7yNiTkRcGBEr9jZWE7ck0bg42ezWnYgYBXwaGJeZWwArABOBbwHfy8yNgaeBA3sbq4lbkmi0SprdmjAUGB4RQ4FVgMeAHYCfVvvPBfbobawmbkmicedks/9ExKSImNVpm7R4nsz5wHeAh2kk7L8BtwDPZGZbddg8YFRvY/XipCTRs4uTmTkFmNLVvogYCUwAxgDPAD8Bdu6DEBczcUsSfXoDzo7Ag5n5F4CI+BnwHmCNiBhaVd2jgfm9PcGATdxtL8+PumMYKCJiUvUbXlrMvxd9qw9zzsPA1hGxCvAiMB6YBVwHfASYBuwH/Ly3J4iS1i6+VkXErMwcV3ccGlj8ezFwRcRxwN5AG3AbcBCNnvY0YM1q7OOZuaBX85u4Bz7/B6qu+PfitctVJZJUGBN3Gexjqiv+vXiNslUiSYWx4pakwpi4JakwJu4BLiJ2joj7qieKfbHueFS/iDgrIp6IiLvqjkX1MHEPYBGxAvADYBdgc2CfiNi83qg0AJxDH99CrbKYuAe2rYA5mflAZr5MY/H+hJpjUs0yczrwVN1xqD4m7oFtFPBIp+/L9UQxSYODiVuSCmPiHtjmAxt2+r5cTxSTNDiYuAe2mcAm1bvqVqTx+qPLao5JUs1M3ANY9dzew4CrgHuAizJzdr1RqW4RMRW4Cdg0IuZFRK/fXagyecu7JBXGiluSCmPilqTCmLglqTAmbkkqjIlbkgpj4lZLRER7RPwhIu6KiJ9Ub7zu7VznRMRHqs9ndPegrYjYLiLe3YtzzI2ItXsbo9SfTNxqlRcz822ZuQXwMvCpzjsjYmhvJs3MgzLz7m4O2Q7oceKWSmLiVn+4Adi4qoZviIjLgLsjYoWIODEiZkbEHRFxMEA0nFo9h/waYN1FE0XEbyNiXPV554i4NSJuj4hrI+KNNH5BHFFV+9tExDoRcXF1jpkR8Z7qZ9eKiKsjYnZEnAFE//4nkXqvV1WP1Kyqst4FuLIaegewRWY+GBGTgL9l5pYRsRLwfxFxNfB2YFMazyBfD7gbOGuJedcBfgRsW821ZmY+FRGnA89n5neq4y4AvpeZN0bE62nchboZcAxwY2Z+PSI+AHj3oYph4larDI+IP1SfbwDOpNHCuDkzH6zGdwLeuqh/DbwO2ATYFpiame3AoxHxmy7m3xqYvmiuzFza86l3BDaPWFxQj4iI1apzfKj62V9FxNO9/HNK/c7ErVZ5MTPf1nmgSp4vdB4CDs/Mq5Y4btc+jGMIsHVmvtRFLFKR7HGrTlcBh0TEMICIGBsRqwLTgb2rHvj6wPZd/OwMYNuIGFP97JrV+HPA6p2Ouxo4fNGXiFj0y2Q6sG81tgswss/+VFKLmbhVpzNo9K9vrV58+z80/l/gJcAfq33n0XgS3itk5l+AScDPIuJ24MJq1y+APRddnAQ+DYyrLn7ezT9WtxxHI/HPptEyebhFf0apz/l0QEkqjBW3JBXGxC1JhTFxS1JhTNySVBgTtyQVxsQtSYUxcUtSYf4fB/Cylp4IxpYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}